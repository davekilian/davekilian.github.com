---
layout: post
title: Paxos From Scratch
author: Dave
draft: true
---

If you've opened a web browser today, chances are you've connected to at least one distributed system that uses Paxos.
I can say this with confidence because Paxos is an extremely popular choice for solving a very common algorithm in distributed systems design.

Paxos's reputation precedes it, for being both confusing to learn and difficult to implement.
This reputation isn't entirely fair: the paper in which Paxos was first published threw many readers by way of a humourous metaphor involving a fictional ancient government.
(In fact, some of Paxos's initial reviewers thought Paxos was just a joke, and didn't realize the paper contained anything of import.)

Lucky for us distributed systems programmers, Paxos is not too much more difficult to learn than Dijkstra's algorithm.
There isn't really any part that's harder than Dijkstra; there's just more material to get through.
To demonstrate this, in this post we will derive Paxos from scratch.

This will prove an important point once and for all:

> _[...Paxos] is among the simplest and most obvious of distributed algorithms. \[...\] This consensus algorithm follows almost unavoidably from the properties we want it to satisfy._
> 
> &mdash; [Paxos Made Simple](https://www.microsoft.com/en-us/research/publication/paxos-made-simple/), Lamport '01

## Motivation

Paxos is an algorithm which implements *distributed consensus*.
What is consensus, and why should we care about algorithms which solve it?

Consensus is a pretty simple concept.
The idea is to synchronize instances of some program running across multiple networked computers, so that all instances share the same value for some variable.
This variable could be anything, even a large data structure containing a whole database of useful information.

Consensus is often used to build higher-level primitives.
Typically, consensus is used to *replicate* the state of some node to other nodes, to guarantee there is no single point of failure.
As long as state is always replicated, it's okay if the 'primary' node goes offline, as any 'secondary' node can take its place.

In this way, consensus allows us to build central authorities into our distributed systems.
This is good, because central authorities allow us to build a number of key higher-level primitives:

* **Locking/Leasing**:
  *Locking* a resource grants exclusive ownership over it to a single node.
  *Leasing* a resource is the same as locking, except the lock also expires automatically after some amount of time.
  A central authority is useful for tracking active locks/leases, and granting new ones for available resources.

* **Sharding**:
  *Sharding* a dataset splits it into chunks called *shards*, and assigns each shard to a different node.
  A central authority is useful for tracking how the dataset has been split, and which nodes have been assigned which shards.

In this way, consensus algorithms underpin many key primitives that are commonly used in distributed system design.

Paxos is essentially the only algorithm used for implementing consensus in modern systems.
That's because it's a great fit for many of these problems:
Paxos is entirely peer-to-peer, so it has no single point of failure.
As long as a majority (at least $\frac{N}{2}+1$) of nodes are online, Paxos stays up and running.
The only downside of Paxos is that it's inefficient, taking a long time and lots of network bandwidth to replicate information.
This means Paxos is only suitable for use with a small amount of data.

## TODO

A simplified buildup:

1. Most trivial case: one server does everything
2. For failures, etc, would be nice to have *replication*
3. Trivial replication: one master, many slaves
4. Network unreliable, so master has to retry forever
5. We want to promote a slave to a master if the master fails
6. Assuming we can do that, network unreliable, leads to split brain
7. Somehow have to handle multiple nodes that think they're 'masters'
8. Master nodes ask a majority of slaves for current value, propagate latest
9. Result: once the majority of slaves agree, masters keep propagating
10. Result: a master which cannot reach a majority of slaves cannot progress
11. But alas, this only works if you have a global synchronous clock for rounds
12. Instead, use 'promises' to prevent the system from backtracking
13. 'Warring proposers' problem, need to back off somehow

I think we now have Synod?
Reread the paper to be sure.
I feel like I at least forgot to include something about learners.

Post II will be the full Parliament algorithm.
Make an endless list of decisions, keeping leadership stable via leases.

Then, as a third post, using this as a general distributed state mechanism.
Chubby lock service, stuff like that.
Also shortcomings, like how to add or remove nodes.

In the fourth post, a working demo.

